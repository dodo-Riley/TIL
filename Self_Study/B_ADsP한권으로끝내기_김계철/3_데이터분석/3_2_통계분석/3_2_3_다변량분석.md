# 3.2.3. 다변량분석

## 1) 상관분석

- 상관분석이란?
    - 데이터 안의 두 변수 간의 관련성을 파악하는 방법
    - 측정 방법에는 피어슨 상관계수, 스피어만 상관계수, 켄달의 순위상관계수 등이 있음
    - 흔히 상관계수라고 하면 피어슨 상관계수를 뜻함
    
    | 사용 척도 | 분석 방법 |
    | --- | --- |
    | 서열 척도 | 스피어만 상관분석 |
    | 등간척도, 비율척도 | 피어슨상관분석, 편상관분석 |

- 상관분석을 위한 기본 가정
    - 상관분석은 변수들 간의 선형성을 충족시켜야 함
        - 즉, 두 변수가 정(+)의 상관이거나 부(-)의 상관의 형태
    - 등분산성이 가정을 충족시켜야함
    - 이상치 유무를 파악하여 제거해야함
    - 변수는 등간 또는 비율 척도로 구성되어야함
        - 서열척도는 순위 상관을 사용
        
- 상관계수
    - 공분산
        - 두 변수 X와 Y를 가정할 때, X의 증감에 따른 Y의 증감 척도로서 $(X_i-X)(Y_i-Y)$의 기대값을 의미하며, cov(X,Y)로 표시함
        - $cov(X,Y)=E(XY)-E(X)E(Y)$
        - 각 변수간의 측정 단위가 달라지면 공분산의 값이 달라지므로 단순히 공분산의 값으로만 두 변수 사이의 관계성을 알기 어려움
        - 두 변수 사이의 일관된 선형관계를 나타내 줄 수 있는 지표를 구하기 위해 두 변수 사이의 공분산을 표준화하는 것이 필요
        - 상관계수는 곧 이 공분산을 표준화시켜 준 값이라고 할 수 있음
        
    - 피어슨 상관계수
        - 대상 변수들의 측정에 사용된 척도가 등간·비율 척도일때, 하나의 변수와 다른 변수와의 관련성을 분석하는 데 이용
        - 변수의 종류나 특정 단위에 관계없는 척도를 구하기 위해 공분산을 X,Y의 표준편차로 나누어 구함
            - $Corr(X,Y)={cov(X,Y)\over\sigma_x\sigma_y}, \quad -1 \le Corr \le 1$
        - 두 변수에 대한 n개의 표본이 주어졌을 때, 이들 표본에 대한 상관계수를 표본상관계수 r로 나타냄
            - $r_{xy}={S_{xy} \over S_xS_y}, \quad S=표준편차, \; -1 \le r \le 1$사
            - 상관계수가 음의 값을 가지면 부(negative)의 상관관계가, 양의 값을 가지면 정(positive)의 상관관계가 있음을 의미함
            - r값이 0에 가까울수록 상관관계가 약한 것을 의미하고 1이나 -1에 가까울수록 강한 상관관계가 있음을 의미함
            - 상관계수의 유의성 검정
                - 상관계수만으로는 두 변수의 유의성을 확인할 수 없음
                - cor.test() 함수를 통해 p-value 확인
                
                ```r
                > a=c(1,2,3,4,5);b=c(1,0,5,7,9)
                > cor.test(a,b,method='pearson')
                
                	Pearson's product-moment correlation
                
                data:  a and b
                t = 5.019, df = 3, p-value = 0.01523
                alternative hypothesis: true correlation is not equal to 0
                95 percent confidence interval:
                 0.3796883 0.9964882
                sample estimates:
                      cor 
                0.9452942
                ```
                
    - 스피어만 상관계수
        - 두 연속형 변수의 분포가 심각하게 정규분포를 벗어난다거나 순위척도 자료일 때 사용
        - 두 데이터의 실제 값 대신 두 값의 순위를 사용해 상관계수를 계산
        - 피어슨 상관계수와 마찬가지로 범위는 -1과 1 사이이며 0에 가까울수록 한쪽의 순위 증가가 다른 쪽의 순위와 연관이 없음을 의미
        - 피어슨 상관계수와 달리 비선형 관계의 연관성을 파악할 수 있다는 장점이 있음
        - 데이터에 순위만 매길 수 있다면 적용이 가능하므로 연속형 데이터에 적합한 피어슨 상관계수와 달리 이산형 데이터, 순서형 데이터에 적용이 가능
        - 스피어만 상관계수의 정의는 아래와 같음
            - $d_i=x_i-y_i \quad (각 \;i번째 \;데이터 \;순위 \;차이)$
            - $\rho=1-{{6 \sum d_i^2}\over{n(n^2-1)}},\quad n=표본 수$
    
    - 켄달의 순위상관계수
        - (X,Y)의 순서쌍 형태로 데이터가 있을 때, x가 커질때 y도 커지면 부합, 반대면 비부합이라고 봄
        - 다른 상관계수들과 마찬가지고 -1과 1 사이의 값을 가지며 1은 부합 데이터쌍의 비율이 100%, -1은 비부합 비율이 100%, 0은 관계없음을 뜻함
        - 정의는 아래와 같음
            - $(부합 데이터 쌍의 수)-(비부합데이터쌍의수)\over{n(n-1)/2}$
            
    - 상관분석의 절차
        - 산점도를 그려서 두 변수의 대략적 관계를 알아봄
        - 상관계수에 필요한 통계량을 구함
        - 상관계수를 구함
        - 모상관계수에 대한 유의성 검정
        - 결정계수를 구함
        - 상관계수와 결정계수를 제시하고 상관분석 결과를 설명

---

## 2) 다차원척도법(MDS, multidimensional scaling)

- 개념 및 목적
    - 다차원 관측값이나 개체들 간의 거리 또는 비유사성을 이용하여 개체들을 원래의 차원보다 낮은 차원의 공간상에 위치시켜 개체들 사이의 구조 또는 관계를 쉽게 파악하는데 목적이 있음
    - 즉, 차원 축소를 통한 개체들의 상대적 위치 등을 통해 개체들 사이의 관계를 쉽게 파악하고자 하는데 목적이 있다고 할 수 있으며, 공간적 배열에 대한 주관적인 해석에 중점이 둠
    - 차원 축소를 위해 개체들 사이의 근접도를 나타내는 척도로서 거리 또는 비유사성을 이용하여 오차 또는 잡음이 포함되기도 함
    - 차원 축소 시 가능하면 축소되기 전후의 개체들 사이의 근접도에 의한 순위가 거의 일치하도록 하는 것이 바람직하며 이를 위해 근접정도를 나타내는 측도로 스트레스(stress)를 이용
    
- 분류
    - 자료의 특성에 따라 분류함
    - 계량적 MDS
        - 구간척도나 비율척도 자료에 근거하여 비유사성이 이루어지는 경우의 분석방법
        - n개의 케이스에 대해서 p개의 특성 변수가 있는 경우, 각 개체들 간의 유클리드 거리행렬을 계산하고 개체들 간의 비유사성 S는 거리제곱의 행렬의 선형함수로 주어지며 이를 공간상에 표현하게 됨
    - 비계량적 MDS
        - 순서척도 자료에 근거하여 비유사성이 측정되는 경우의 분석방법
        - 개체들 간의 거리가 순서로 주어진 경우에는 순서척도 데이터를 거리의 속성과 같도록 변환시키는 과정(monotone transformation)을 거쳐 MDS분석에 들어가게 됨
    
- stress와 적합도 수준
    - 각 개체들을 공간상에 표현하기 위한 방법은 stress나 s-stress를 부적합도 기준으로 사용
    - stress값은 0과 1사이의 값을 취하며 0으로 작아질수록 적합된 모형이 적절하다고 판단
    - $s=\sqrt{{{\sum_{i=1,j=1}^n(d_{ij}-\hat{d_{ij}})^2}\over{\sum_{i=1,j=1}^n(\hat{d_{ij}})^2}}}$
    
- 다차원척도 그래프
    
    ```r
    > data("eurodist")
    > print(eurodist)
                    Athens Barcelona Brussels Calais Cherbourg Cologne Copenhagen Geneva
    Barcelona         3313                                                              
    Brussels          2963      1318                                                    
    Calais            3175      1326      204                                           
    Cherbourg         3339      1294      583    460                                    
    Cologne           2762      1498      206    409       785
    #(이하생략)
    > loc = cmdscale(eurodist)
    > loc
                            [,1]        [,2]
    Athens           2290.274680  1798.80293
    Barcelona        -825.382790   546.81148
    Brussels           59.183341  -367.08135
    Calais            -82.845973  -429.91466
    #(이하생략)
    > x = loc[,1];y=loc[,2]
    > plot(x,y,type='n',main='eurodis')
    > text(x,y,rownames(loc),cex=.8,col='red')
    > abline(v=0,h=0)
    ```
    
    ![Untitled](3%202%203%20%E1%84%83%E1%85%A1%E1%84%87%E1%85%A7%E1%86%AB%E1%84%85%E1%85%A3%E1%86%BC%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%205e716d665c2f426294bcfeae671fc9b5/Untitled.png)
    

---

## 3) 주성분분석(PCA, principal component analysis)

- 쉽게 이해하기(참고 : [https://huidea.tistory.com/44](https://huidea.tistory.com/44))
    - 온도, 습도, 강수량, 풍속, 태풍여부 등의 feature가 존재한다고 하자
    - 습도와 강수량, 풍속와 태풍여부 등 상관관계가 강한 피쳐가 존재하며 이를 하나의 새로운 피쳐로 합치는 것이 주성분 분석
    - 이때, 기존 피쳐가 가지는 정보의 소실이 존재함
    - 이를 최소화하는 것이 필요
    - 예를 들어, 2차원 벡터공간의 데이터가 있다고 가정
    - 이를 1차원으로 축소하는 방법으로 y축 성분을 제거하거나 x축 성분을 제거할 수 있음
    - 하지만 이러한 방법은 기존 데이터들이 가지던 정보를 유실하는 것임
    - 그림으로 살펴보았을 때도, 다른데이터이지만 아예 같은 특성을 가지는 데이터가 될 수도 있음(겹치게 됨)
    - 따라서 데이터들이 겹치지 않을 수 있는 새로운 축을 찾아 여기에 기존 데이터를 정사영(벡터로 생각하면 내적)시켜야함
    - 이러한 새로운 축은 상당히 많지만 우리는 가능한한 기존 데이터가 겹치지 않고 최대한 퍼지도록(분산이 커지도록)하는 축을 찾는것이 좋음
    - 이러한 과정은 곧 공분산 행렬에서 고유 벡터/고유값을 구하고 가장 분산이 큰 ****방향을 가진 고유벡터에 입력데이터를 선형변환하는 것
    - 다차원 데이터를 2차원으로 축소시킨다면 하나의 고유벡터와 이에 직교하는(각 고유벡터간의 상관성을 없앨 수 있는) 또 하나의 고유벡터를 찾음

- 주성분분석의 개념
    - 표본 수와 변수가 상당히 많으면 이를 파악하는 일은 쉽지 않음
    - 1933년 Hotelling은 p개의 변수를 p보다 적은 m개의 상호독립적인 변수로 종합화하는 주성분 분석 방법을 개발
    - 주성분분석은 서로 연관된 여러 변수의 차원(변수의 수)을 축소하는 분석 기법
    - 데이터셋의 차원을 축소하되, 가능한 많은 정도(변동, variation)를 보존하고자 하는 분석기법
    
- 요인분석(factor analysis)과의 차이
    - 요인분석 : 여러 개의 서로 관련이 있는 변수들로 구성된 데이터에서 이 변수를 설명할 수 있는 새로운 공통적으로 부여 가능한 요인을 파악하는 분석 방법
    - 주성분분석은 정보의 손실을 최소화해서 단순하게 데이터를 축소하는 방법
    - 요인분석은 자료의 축소라는 의미는 물론 데이터에 내재적 속성까지 찾아내는 방법

- 차원(dimension)
    - 공간 내에 있는 점 등의 위치를 나타내기 위해 필요한 축의 개수
    - 데이터 분석의 측면에서 차원은 곧 변수의 수로 이해할 수 있음
    - 차원의 저주 : 변수의 증가 → 차원의 증가 → 과적합 발생
    - 차원 축소와 주성분분석이 필요한 이유
        - 차원의 저주로 복잡함 발생
        - 복잡함(과적합 등) 탈피와 시각화의 용이를 위해 상관있는 변수들끼리의 정보 단순화
        - 차원 축소 시행
        - 주성분 분석은 차원 축소를 위해 모든 변수를 조합하여 해당 데이터를 잘 설명할 수 있는 중요 성분을 가진 새로운 변수를 추출하는 것
        
- 주성분분석을 이해하기 위한 원리
    - 원 변수들의 선형결합을 통해 무상관(uncorrelated)인 변수들의 집합(이를 인자 또는 주성분이라함)을 계산
    - 주성분의 수는 원 변수의 차원 수만큼 만들어질 수 있으며, 이 가운데 소수의 처음 몇 개의 주성분이 원변수들이 가지는 변동의 대부분을 가지도록 순서화
    - 고차원인 원 자료의 값을 저차원의 주성분 값만으로 변환(다소의 정보 손실 불가피)
    - 이와 같은 차원 축소는 데이터를 저차원의 공간으로 시각화할 수 있으며, 데이터의 축약을 통해 알고리즘의 계산 시간을 크게 감소시킴
    - 또한, 많은 통계적 모형은 공변량 간의 높은 상관계수로 인해 어려움이 존재하며 PCA는 서로 간의 상관성이 없는 공변량들의 선형결합을 제공하는 데 이용될 수도 있음
    
    - 고유값(eigenvalue)과 고유벡터(eigenvector)
        - $n \times n$  정방행렬 A에 대하여 $Ax=\lambda x$를 만족하는 0이아닌 열벡터 x를 고유벡터, 상수 람다를 고유값이라 정의
        - 고유벡터는 선형변환에 의해 방향은 보존되고 크기만 변화되는 방향 벡터
        - 고유값은 고유벡터의 변화되는 크기 정도를 나타내는 값

- 공분산행렬
    - 행렬이란 선형변환이고 하나의 벡터공간을 선형적으로 다른 벡터 공간으로 매핑하는 기능을 가짐
    - 변수들의 분산과 공분산을 이용해 나타낸 행렬이 공분산행렬
        - 변수 x1과 x2를 예로 들어보자
        - x1의 분산을 3, x2의 분산을 4, x1과 x2의 공분산을 2라고하면 공분산행렬은 아래와 같음
        - $\begin{pmatrix} 3 & 2 \\ 2 & 4 \end{pmatrix}$
        - 공분산행렬은 대칭행렬
    - 고유벡터는 그 행렬이 벡터에 작용하는 주축의 방향을 나타내므로 공분산 행렬의 고유벡터는 데이터가 어떤 방향으로 분산되어 있는지를 나타낸다고 할 수 있음
    - 고유값은 고유벡터 방향으로 얼마만큼의 크기로 벡터공간이 퍼지는지를 의미하므로 고유값이 큰 순서대로 고유벡터를 정렬하면 결과적으로 중요한 순서대로 주성분을 구하는 것이 됨
    - 데이터를 공분산행렬을 적용하여 선형변환한다는 것은 아래와 같음
        - 위 공분산 행렬에서 3은 x축 방향으로 퍼진 정도를 말함
        - 4는 y축으로 퍼진 정도를 말함
        - 2는 x,y축 방향으로 함께 퍼진정도를 말함
        
- 주성분분석 절차
    - 데이터 특성 파악 : 상관분석을 통한 변수간 상관관계 파악
    - 가중계수 추출 : 공분한 행렬에 대한 고유값 분해 이용
    - 차원 축소 : 상관계수 및 상관행렬
    - 보유 주성분 개수 판정 : 전체 변이에 대한 공헌도, 고유값 크기
    
- 주성분 분석의 문제점
    - 측정 단위에 따라 분산이 크게 달라짐
        - 표준화하는 경우 : 특정 단위가 다른 경우, 상관행렬로부터 시작하는 주성분분석
        - 표준화하지 않는 경우 : 자료의 단위가 동일한 경우, 공분산행렬로부터 시작하는 주성분분석, 모집단의 특성을 반영할 수 있음
        
- 주성분분석의 결정기준
    - 데이터 차원을 감소시키는 것이 주성분분석이고 가장 중요한 포인트는 주성분을 몇개까지 고를지 결정해야하는 것
        - 성분들이 설명하는 분산의 비율 : 누적 비율을 확인하면 주성분들이 설명하는 전체 분산 양을 알 수 있고, 연구에 따라 다르지만 총 분산의 비율이 70~90% 사이가 되는 주성분의 개수를 선택
        - Kaiser 기준을 사용하는 경우 고유값이 1보다 큰 주성분만 사용
        - Scree plot을 이용해 주성분 분산의 감소가 급격하게 줄어들어 주성분의 개수를 늘릴때 얻게되는 정보의 양이 상대적으로 미미한 지점에서 주성분의 개수를 정할 수 있음
        - 주성분분석 결과 해석하기
            
            ```r
            > library(datasets)
            > data("USArrests")
            > head(USArrests)
                       Murder Assault UrbanPop Rape
            Alabama      13.2     236       58 21.2
            Alaska       10.0     263       48 44.5
            Arizona       8.1     294       80 31.0
            Arkansas      8.8     190       50 19.5
            California    9.0     276       91 40.6
            Colorado      7.9     204       78 38.7
            
            > fit = prcomp(USArrests,scale=TRUE) # 주성분분석함수, scale=True는 표준화의미
            > summary(fit)
            Importance of components:
                                      PC1    PC2     PC3     PC4
            Standard deviation     1.5749 0.9949 0.59713 0.41645
            Proportion of Variance 0.6201 0.2474 0.08914 0.04336
            Cumulative Proportion  0.6201 0.8675 0.95664 1.00000
            
            > biplot(fit)
            ```
            
            ![Untitled](3%202%203%20%E1%84%83%E1%85%A1%E1%84%87%E1%85%A7%E1%86%AB%E1%84%85%E1%85%A3%E1%86%BC%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%205e716d665c2f426294bcfeae671fc9b5/Untitled%201.png)
            
            - pc1이 전체 분산의 62%를 설명, 정보손실은 100-62=38%
            - 두번째 주성분이 24.7%설명, 누적비율이 86.7%이므로 여기까지 선택할 수 있음
            - biplot은 1주성분과 2주성분을 이용해 그린 그래프
                - 1주성분에 대해 murder, assault, rape가 상관계수가 크므로 해당 변수들에 대해 큰 가중치가 적용
                - 1주성분 기준 범죄율 상위 그룹은 플로리다, 네바다, 캘리포니아
                - 하위그룹은 노스 다코타
                - 2주성분 기준으로 인구관련 상위 그룹은 캘리포니아
                - 하위그룹은 미시시피