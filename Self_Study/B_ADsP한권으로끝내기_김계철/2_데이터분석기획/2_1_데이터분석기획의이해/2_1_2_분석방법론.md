# 2.1.2. 분석 방법론

## 1) 분석 방법론 개요

- 기업의 합리적 의사결정의 중요성
    - 최근 기업 경쟁력을 향상하기 위하여 데이터 분석 및 활용의 중요성이 강조
    - 기존의 경험과 감에 의한 의사결정에는 한계가 있음을 인식하고 데이터 기반의 의사결정을 위하여 많은 노력을 기울이는 중
    - 고정관념, 편향된 생각, 프레이밍 효과 등은 기업의 합리적 의사결정을 가로막는 장애요소(프레이밍 효과 : 문제의 표현방식에 따라 같은 사건이나 상황임에도 불구하고 개인의 판단이나 선택이 달라질 수 있는 형상)
    - 결국 기업문화의 변화와 업무 프로세스 개선이 필요
    
- 분석 방법론
    - 데이터 분석을 체계화하는 절차와 방법을 정리한 것
    - 일반적으로 계층적 프로세스 모델(stepwised process model)의 형태로 구성
        - 단계 : 최상위 계층으로 프로세스 그룹을 통해 완성된 단계별 완료보고서가 생성
        - 태스크 : 단계를 구성하는 단위 활동으로 구성
        - 스텝 : 마지막 계층으로 입력 자료, 처리 및 도구, 출력 자료로 구성된 단위 프로세스
    - 분석 방법론의 구성 요소
        - 상세한 절차(procedure)
        - 방법(methods)
        - 도구와 기법(tools & techniques)
        - 템플릿과 산출물(templates & outputs)
        
- 방법론의 생성 과정
    - 개인의 암묵지가 조직의 형식지로 발전하는 형식화 과정을 거치고, 이를 체계화하여 문서화하고 이를 최적화된 형식지로 전개함으로써 방법론이 만들어질 수 있음
    - 이렇게 만들어진 방법론은 다시 개인에게 전파되고 활용되는 내재화 과정을 거쳐 암묵지로 발전하는 선순환 과정이 진행되면서 조직 내 방법론이 완성될 수 있음
    - 방법론은 적용 업무의 특성에 따라 다양한 모델을 가질 수 있음
    - 암묵지 (형식화)→ 형식지 (체계화)→ 방법론 (내재화)→ 암묵지 (형식화)→ 형식지 (체계화) → 방법론 (내재화)→ 암묵지 (형식화)→ (반복)
    
- 다양한 방법론에 따른 분석모형 프로세스
    
    
    | 구분 | 폭포수 | 나선형 | 프로토타입 |
    | --- | --- | --- | --- |
    | 개념 | 분석 → 설계 → 개발 → 테스트 | 요구분석 → 프로토타입 → 평가 → 상세개발 및 취소 | [계획 → 위험분석 → 개발 → 고객평가]를 반복 |
    | 특징 | 순차적 접근 | 프로토타입 개발 | 위험분석, 반복개발 |
    | 장점 | 이해가 용이, 관리가 편리 | 요구분석 용이, 개발 타당성 검증 가능 | 변경에 유연한 대처 가능, 위험성 감소 |
    | 단점 | 전반부 요구분석 어려움 | 프로토타입 폐기에 따른 비용증가 | 단계 반복에 따른 공정 관리 어려움 |
    - 폭포수(waterfall) 모델
        - 단계별로 철저한 검토와 승인 과정을 거쳐 확실히 매듭짓고 다음 단계로 진행하는 모델
        - 하향식(top down) 진행
        - 문제나 개선사항이 발견되면 전 단계로 돌아가는 피드백 과정 수행
    - 나선형(spiral) 모델
        - 여러 번의 개발 과정을 거쳐 점진적으로 프로젝트를 완성해가는 모델
        - 처음 시도하는 프로젝트에 적용 용이
        - 반복에 대한 관리체계를 효과적으로 갖추기 못한 경우 프로젝트 진행이 어려움
        - 대규모 시스템 소프트웨어 개발에 적합
    - 프로토타입(prototype) 모델
        - 사용자의 요구 사항이나 데이터를 정확히 규정하기 어렵고 데이터 소스도 명확히 파악하기 어려운 상황에서 일단 분석을 시도해보고 그 결과를 확인해가면서 반복적으로 개선해 나가는 방법
        - 사용자의 요구 사항을 분석한 후, 프로토타입을 개발하여 평가를 받고 그 결과에 따라 개선이나 재분석, 개발 실행 등을 진행

---

## 2) KDD 분석 방법론

- KDD(knowledge discovery in database)
    - 1996년 Fayyad가 체계적으로 정리한 데이터마이닝 프로세스
    - 데이터 마이닝, 기계학습, 인공지능, 패턴인식, 데이터 시각화 등에서 응용될 수 있는 구조
- 분석 절차
    
    
    | 순서 | 단계 | 내용 |
    | --- | --- | --- |
    | 1 | 데이터 선택(selection) | - 비즈니스 도메인에 대한 이해와 프로젝트 목표 설정
    - 데이터 마이닝에 필요한 목표 데이터 선택 |
    | 2 | 데이터 전처리(preprocessing) | 데이터셋이 포함되어 있는 잡음, 이상값, 결측치 등을 식별하고 처리 |
    | 3 | 데이터 변환(transformation) | 분석 목적에 맞는 변수를 선택하거나 데이터의 차원을 축소하여 데이터 마이닝을 효율적으로 적용할 수 있도록 변경  |
    | 4 | 데이터 마이닝(data mining) | 변환된 데이터셋을 이용해 목적에 맞는 기법과 알고리즘을 선택하여 데이터의 패턴을 찾거나 분류, 예측 등의 마이닝 작업 시행 |
    | 5 | 데이터 마이닝 결과평가(interpretation/evaluation) | 결과에 대한 해석과 평가 및 활용 |

---

## 3) CRISP-DM 분석 방법론

- CRISP-DM(cross industry standard process for data mining)
    - 1996년 유럽연합의 ESPIRIT에서 있었던 프로젝트에서 시작
    - 계층적 프로세스 모델로서 4개 레벨로 구성
        - 단계(phases) : 최상위 레벨
        - 일반화 태스크(genetic tasks) : 데이터 마이닝의 단일 프로세스를 완전하게 수행하는 단위
        - 세분화 태스크(specialized task) : 일반화 태스크를 구체적으로 수행하는 레벨
        - 프로세스 실행(process instance) : 데이터 마이닝을 위한 구체적인 실행을 포함

- CRISP-DM 분석 절차
    
    
    | 순서 | 단계 | 내용 |
    | --- | --- | --- |
    | 1 | 업무 이해(business understanding) | 업무 목적 파악, 상황 파악, 데이터 마이닝 모표 설정, 프로젝트 계획 수립 |
    | 2 | 데이터 이해(data understanding) | 초기 데이터 수집, 데이터 기술 분석, 데이터 탐색, 데이터 품질 확인 |
    | 3 | 데이터 준비(data preparation) | 분석용 데이터셋 선택, 데이터 정제, 데이터 통합, 데이터 포맷팅 |
    | 4 | 모델링(modeling) | - 모델링 기법 선택, 모델 테스트 계획 설계, 모델작성, 모델 평가
    - 다양한 모델링 기법과 알고리즘을 선택하고 모델링 과정에서 사용되는 파라미터를 최적화
    - 찾아낸 모델은 테스트용 데이터셋으로 평가하여 과적합 등의 문제를 발견하고 대응방안을 마련 |
    | 5 | 평가(evaluation) | 분석 결과 평가, 모델링 과정 평가, 모델 적용성 평가 |
    | 6 | 전개(deployment) | 전개 계획 수립, 모니터링과 모델링 유지보수 계획 수립, 프로젝트 종료 보고서 작성, 프로젝트 리뷰 |
    - 6단계로 구성되어 있으며, 단계 간 피드백을 통해 완성도를 높이게 되어 있음
    
- KDD와 비교
    
    
    | KDD | CRISP-DM |
    | --- | --- |
    | 분석 대상 비즈니스 이해 | 업무 이해 |
    | 데이터 선택 | 데이터 이해 |
    | 데이터 전처리 | 데이터 이해 |
    | 데이터 변환 | 데이터 준비 |
    | 데이터 마이닝 | 모델링 |
    | 데이터 마이닝 결과평가 | 평가 |
    | 데이터 마이닝 활용 | 전개 |

---

## 4) 빅데이터 분석 방법론

- 빅데이터 분석 방법론
    - 계층적 프로세스 모델로서 3계층으로 구성
        - 단계
            - 프로세스 그룹을 통하여 완성된 단계별 산출물이 생성되어야 함
            - 각 단계는 기준선(baseline)으로 설정되어 관리되어야 하며 버전관리(configuration management) 등을 통하여 통제가 이루어져야함
        - 태스크
            - 각 단계를 구성하는 단위 활동
            - 각 태스크는 물리적 또는 논리적 단위로 품질검토의 항목이 될 수 있음
        - 스텝
            - WBS(work breakdown structure)의 워크패키지에 해당됨
            - 입력자료, 처리 및 도구, 출력자료로 구성된 단위 프로세스
            
- 빅데이터 분석 방법론 분석 절차
    
    
    | 순서 | 단계 | 태스크 | 내용 |
    | --- | --- | --- | --- |
    | 1 | 분석 기획(planning) | 비즈니스 이해 및 범위 설정 | 프로젝트에 참여하는 관계자들(stakeholders)의 이해를 일치시키기 위하여 구조화된 프로젝트 범위 정의서인 SOW(statement of work)를 작성 |
    |  |  | 프로젝트 정의 및 계획 수립 | - 프로젝트의 목표 및 KPI(핵심성과지표), 목표 수준 등을 구체와하여 상세 프로젝트 정의서를 작성
    - 프로젝트 수행 계획서를 작성하는 단계로서 프로젝트의 목적 및 배경, 기대효과, 수행방법, 일정 및 추진조직, WBS(work breakdown strueture)를 작성 |
    |  |  | 프로젝트 위험계획 수립 | - 데이터 분석 위험 식별, 계획 수립 단계에서 빅데이터 분석 프로젝트를 진행하면서 발생 가능한 모든 위험을 식별
    - 예상되는 위험에 대한 대응은 회피(avoid), 전이(transfer), 완화(mitigate), 수용(accept)으로 구분하여 위험 관리 계획서를 작성 |
    | 2 | 데이터 준비(preparing) | 필요 데이터 정의 | 정형/비정형/반정형 등의 모든 데이터를 포함하고 데이터의 속성, 데이터 오너, 데이터 관련 시스템 담당자 등을 포함하는 데이터 정의서(메타데이터 정의서, ERD(entity relationship diagram))를 작성 |
    |  |  | 데이터 스토어 설계 | - 정형 데이터 : RDBMS를 사용
    - 비정형/반정형 데이터 : 하둡, NoSQL 등
    - 데이터의 효율적인 저장과 활용을 위해 논리적, 물리적 데이터 스토어를 설계 |
    |  |  | 데이터 수집 및 정합성 점검 | 크롤링 등의 데이터 수집을 위한 ETL(extract transform load) 등의 다양한 도구와 API,  스크립트 프로그램 등을 이용하여 데이터를 수집하고, 이를 스토어에 저장 |
    | 3 | 데이터 분석(analyzing) | 분석용 데이터 준비 | - 분석 기획 단계에서 비즈니스 이해, 도메인 문제점 인식, 프로젝트 정의 등을 이용하여 프로젝트의 목표를 정확하게 인식
    - 데이터 스토어로부터 분석에 필요한 데이터를 추출 |
    |  |  | 텍스트 분석 | 감성 분석(sentimental analysis), 토픽 분석(topic analysis), 오피니언 분석(opinion analysis), 소셜 네트워크 분석(social network analysis) 등을 실시하여 텍스트로부터 분석 목적에 맞는 적절한 모델을 구축 |
    |  |  | 탐색적분석(EDA, exploratory data analysis) | - 다양한 관점별로 기초 통계량을 산출하고 데이터의 분포와 변수 간의 관계 등 데이터 특성 및 데이터의 통계적 특성을 이해하고 모델링을 위한 기초 자료로 활용
    - 데이터 시각화 |
    |  |  | 모델링 | - 분석용 데이터를 이용한 가설 설정을 통해 통계 모델을 만들거나 기계학습을 이용한 데이터의 분류, 예측, 군집 등의 기능을 수행하는 모델을 만드는 과정
    - 데이터 분할 : train/test set으로 나누어 과적합 방지
    - 데이터 모델링
    - 모델 적용 및 운영 방안 : 모델에 대한 상세한 알고리즘 작성 |
    |  |  | 모델 평가 및 검증 | - 프로젝트 정의서의 모델 평가 기준에 따라 모델을 객관적으로 평가하고 품질관리 차원에서 모델 평가 프로세스를 진행
    - test 셋을 이용하여 모델 검증 |
    | 4 | 시스템 구현(developing) | 설계 및 구현 | - 모델링 태스크에서 정의된 알고리즘 설명서와 데이터 시각화 보고서를 이용하여 시스템 및 아키텍쳐 설계, 사용자 인터페이스 설계를 진행
    - 설계서를 바탕으로 패키지를 활용하여 프로그램 구축 |
    |  |  | 시스템 테스트 및 운영 | 단위테스트, 통합테스트, 시스템 테스트 실시 |
    | 5 | 평가 및 전개(deplying) | 모델 발전 계획 수립 | 개발된 모델의 지속적인 운영과 기능 향상을 위한 발전 계획을 상세하게 수립 |
    |  |  | 프로젝트 평가 보고 | - 프로젝트의 성과를 정량적, 정성적으로 평가하고 진행 과정에서 산출된 지식, 프로세스, 출력 자료를 지식 자산화
    - 프로젝트 최종보고서를 작성 |
    - 용어 설명
        - WBS(work breakdown structure) : 작업 분할 구조도, 전체 업무를 분류하여 구성 요소로 만든 후 각 요소를 평가하고 일정별로 계획하며 그 것을 완수할 수 있는 사람에게 할당해주는 역할을 함
        - 위험에 대한 대응 방법 4가지
            - 회피(avoid) : 위험의 영향도가 너무 커서 위험을 회피
            - 전이(transfer) : 위험의 영향을 다른사람(방법)으로 전가시킴, 하자보수보증 등이 예
            - 완화(mitigation) : 어떠한 방법을 통해 영향도를 감소시키는 방법
            - 수용(acception) : 위험을 고스란히 수용하고 인력 투입 등의 방법으로 대응 처리
        - ETL(extract transform load) : 데이터의 추출, 변환, 적재의 약자로 비즈니스 인텔리전스 구현을 위한 기본 구성 요소 가운데 하나, ETL 툴은 다양한 원천 데이터를 취합해 데이터를 추출하고 하나의 공통된 포맷으로 변환하여 데이터 웨어하우스나 데이터 마트에 적재하는 툴을 의미
        - 크롤링 혹은 스크래이핑(crawling, scraping)) : 웹페이지를 그대로 가져와서 데이터를 추출해내는 행위
        - 의사코드(pseudocode) : 특정 프로그래밍 언어의 문법에 따라 쓴 것이 아니라, 일반적인 언어로 코드를 흉내 내어 알고리즈을 써 놓은 코드