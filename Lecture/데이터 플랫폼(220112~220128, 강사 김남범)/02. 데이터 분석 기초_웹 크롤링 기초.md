# 2. 데이터 분석 기초_웹 크롤링 기초

- 웹 페이지 접속 및 해당 페이지 HTML 다운로드(크롬드라이버 활용)
  
    ```python
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    
    service = Service('../chromedriver/chromedriver.exe')
    driver = webdriver.Chrome(service=service)
    
    url = 'https://www.naver.com/'
    driver.get(url) # 웹 페이지 접속
    html = driver.page_source # HTML 다운로드
    ```
    
- HTML에서 원하는 정보 찾기(BeautifulSoup 활용)
  
    ```python
    from bs4 import BeautifulSoup
    
    html = '''
    <html>
        <head>
        </head> # 태그의 시작과 끝
        <body>
            <h1> 우리동네시장</h1>
                <div class = 'sale'>
                    <p id='fruits1' class='fruits'>
                        <span class = 'name'> 바나나 </span>
                        <span class = 'price'> 3000원 </span>
                        <span class = 'inventory'> 500개 </span>
                        <span class = 'store'> 가나다상회 </span>
                        <a href = 'http://bit.ly/forPlaywithData' > 홈페이지 </a>
                    </p>
                </div>
                <div class = 'prepare'>
                    <p id='fruits2' class='fruits'>
                        <span class ='name'> 파인애플 </span>
                    </p>
                </div>
        </body>
    </html>
    '''
    soup = BeautifulSoup(html, 'html.parser') # 다운로드한 html 파싱
    
    tags_span = soup.select('span') # 태그명이 span인 데이터를 저장
    len(tags_span) # 5
    type(tags_span) # 리스트처럼 생겼지만 다른 타입 확인
    tags_p = soup.select('p') # 태그명이 span인 데이터를 저장
    len(tags_p) # 2
    
    ids_fruits1 = soup.select('#fruits1') # id가 fruits1인 데이터(#사용)
    class_price = soup.select('.price') # class가 price인 데이터(.사용)
    tags_span_class_price = soup.select('span.price') # 태그명과 class를 한번에 만족하는 데이터
    
    tags_banana1 = soup.select('#fruits1>span.name') # 해당 id 아래 태그명과 클래스를 만족하는 데이터
    tags_banana2 = soup.select('div.sale>#fruits1>span.name') # 부모 태그를 사용함으로써 좀 더 구체적인 데이터를 찾음
    tags_banana3 = soup.select('div.sale span.name') # 공백을 이용하면 상위 태그 아래의 모든 태그에 대해 데이터를 찾음
    
    name = soup.select('span.name')
    name0 = name[0] # 리스트와 같은 방식으로 인덱싱
    name1 = name[1]
    name0.text # 태그에서 화면에 보이는 텍스트 부분만 가져오기
    
    tags = soup.select('a')
    tag = tags[0]
    content = tag.text
    print(content)
    link = tag['href'] # 태그 내 href 속성값 link에 저장
    print(link)
    ```
    
- 멜론 top100 차트에서 곡 정보 추출하기(BeautifulSoup 활용)
  
    ```python
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from bs4 import BeautifulSoup
    
    service = Service('../chromedriver/chromedriver.exe')
    driver = webdriver.Chrome(service=service)
    
    url = 'https://www.melon.com/chart/index.htm'
    driver.get(url)
    html = driver.page_source # 차트가 있는 웹 페이지 접속 및 다운로드
    
    soup = BeautifulSoup(html, 'html.parser') # 파싱
    songs = soup.select('tbody>tr') # tbody 태그 아래 tr 태그 데이터만 저장
    len(songs) # 데이터가 100개인 것 확인
    
    for song in songs :
        title = song.select('div.ellipsis.rank01 > span > a')[0].text # 곡 제목 추출, 클래스의 공백도 .으로 입력
        singer = song.select('div.ellipsis.rank02 > a')[0].text # 가수 추출
        rank = song.select('div.wrap.t_center > span')[0].text # 순위 추출
        print(rank, title, singer, sep=',')
    ```

- 멜론 top100 차트에서 곡 정보 추출하기(Selunium 활용)(최근 변경점이 존재하므로 추후 재작성 예정)

  ```python
  from selenium import webdriver
  from selenium.webdriver.chrome.service import Service
  
  service = Service('../chromedriver/chromedriver.exe')
  driver = webdriver.Chrome(service=service)
  
  url = '<https://www.melon.com/chart/index.htm>'
  driver.get(url)
  
  songs = driver.find_elements_by_css_selector('table>tbody>tr') # tbody 태그 아래 tr 태그 데이터만 저장
  
  for song in songs :
      title = song.find_elements_by_css_selector('div.ellipsis.rank01 > span > a')[0].text # 곡 제목 추출
      singer = song.find_elements_by_css_selector('div.ellipsis.rank02 > a')[0].text # 가수 추출
      rank = song.find_elements_by_css_selector('div.wrap.t_center > span')[0].text # 순위 추출
      print(rank, title, singer, sep=',') 
  ```

- 크롤링 방식의 장단점 비교

  |                | Selenium+BeautifulSoup                   | Selenium                 |
  | -------------- | ---------------------------------------- | ------------------------ |
  | 웹 페이지 접속 | HTML 정보 다운로드 후 브라우저 영향 없음 | 웹 페이지 연결 유지 필요 |
  | 웹 페이지 동작 | 불가능                                   | 클릭, 입력 등 조작 가능  |
  | 크롤링 속도    | 빠름                                     | 느림                     |