# 4. 지도학습_분류

## 1) 분류 개념 알아보기

- 분류란?
    - 주어진 입력값이 어떤 클래스에 속할지에 대한 결과값을 도출하는 알고리즘
    - 예측 목표와 데이터 유형에 따라 다양한 분류 알고리즘을 적용
        - 트리 구조 기반 : 의사결정나무, 랜덤포레스트 등
        - 확률 모델 기반 : 나이브 베이즈 분류기 등
        - 결정 경계 기반 : 선형 분류기, 로지스틱 회귀 분류기, SVM 등
        - 신경망 : 퍼셉트론, 딥러닝 모델 등
        - 그 외 다양한 알고리즘이 존재

## 2) 의사결정나무 - 모델 구조

- 의사결정나무란?
    - 스무고개와 같이 특정 질문들, 즉 기준이나 조건을 통해 정답을 찾아가는 모델
    - 뿌리 마디(root node)에서 시작해 중간 마디(internal node)들을 거쳐 끝 마디(terminal node)까지 순차적으로 분류가 진행
    
    ![Untitled](4%20%E1%84%8C%E1%85%B5%E1%84%83%E1%85%A9%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8_%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2053d37bc26c41475c9f300b8d92e25fc1/Untitled.png)
    

- 의사결정나무의 특징
    - 결과가 직관적이며 해석하기 쉬움
    - 깊이가 깊어질수록 과적합 문제가 발생할 가능성이 큼
        - 이를 방지하기 위해 가지치기(pruning) 진행
        - 즉, 최대 깊이를 강제로 설정함으로써 과적합 문제를 방지
    - 학습이 끝난 트리의 작업 속도가 매우 빠름

## 3) 의사결정나무 - 불순도

- 의사결정나무의 분리 기준은 데이터의 불순도를 최소화할 수 있는가에 따라 결정되며, 의사결정나무의 분류는 각 노드의 불순도를 최소화하는 방향으로 진행됨

- 불순도(impurity)
    - 서로 다른 데이터가 섞여있는 정도
    - 측정 방법
        - 지니 불순도(Gini impurity)
            - 자식 노드의 데이터 개수와 지니 계수를 곱한 값들의 합을 부모 노드의 데이터 개수로 나눈 값
            - $Gini\:index=1-P(yes)^2-P(no)^2$
            - $Gini\:impurity={1 \over N} \times {(n_1Gini_1+n_2Gini_2)}$
            - 예는 아래와 같음
                
                ![Untitled](4%20%E1%84%8C%E1%85%B5%E1%84%83%E1%85%A9%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8_%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2053d37bc26c41475c9f300b8d92e25fc1/Untitled%201.png)
                
        - 엔트로피 등 다른 방법도 존재

## 4) 분류 평가 지표

- 분류가 잘 되었는지 평가하는 지표

- 분류 평가 지표의 종류
    - 혼동 행렬(Confusion matrix)
        - 목표변수의 실제 범주와 모형에 의해 예측된 분류 범주 사이의 관계를 나타내는 교차표 형태로 정리한 행렬
            
            
            |  | 예측 positive | 예측 negative |
            | --- | --- | --- |
            | 실제 positive | TP(true positive) | FN(false negative) |
            | 실제 negative | FP(false positive) | TN(true negative) |
        - FP의 경우, 제 1종 오류
        - FN의 경우, 제 2종 오류
        
    - 정확도(accuracy)
        - 전체 데이터 중에서 제대로 분류된 데이터의 비율
        - 모델이 얼마나 정확하게 분류하는지를 나타냄
        - $Accuracy={{TP+TN} \over {TP+TN+FP+FN}}$
        - 클래스의 비율이 불균형할 경우, 평가 지표의 신뢰성을 잃을 가능성이 존재
        
    - 정밀도(precision)
        - positive로 분류한 데이터 중 실제 positive인 데이터의 비율
        - $precision = {{TP} \over {TP+FP}}$
        - 실제로 negative인 데이터를 positive라고 판단하면 안되는 경우 사용(negative가 중요한 경우)
            - 예로, 스팸 메일 분류 문제
            - 스팸일 경우 positive, 아니면 negative
            - 일반 메일을 스팸으로 분류하면 중요한 메일을 전달받지 못할수도 있음
    
    - 민감도(sensitivity, =recall(재현율))
        - 실제 positive인 데이터 중에서 positive로 예측한 데이터의 비율
        - $recall={{TP} \over {TP+FN}}$
        - 실제로 positive인 데이터를 negative라고 판단하면 안되는 경우 사용(positive가 중요한 경우)
            - 예로, 악성 종양 여부 문제
            - 악성일 경우 positive, 아니면 negative
            - 악성을 양성으로 잘못 예측했을 경우, 치료를 제 때 받지 못할 수 있음